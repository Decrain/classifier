一天清晨，我被一個客戶電話驚醒，客戶異常焦急，尋問CDN能不能幫助他們解決「秒殺」的問題，他們昨天剛剛進行了「整點秒殺活動」，結果併發量過大，導致服務宕機，用戶投訴。

該公司是一家P2P理財網站，常有用戶在整點搶購高利率理財產品的「整點秒殺活動」。如上圖所示，終端用戶請求先通過前端負載均衡，然後到達運行實際電商邏輯的WebServer；再下層是運行在VM上的8臺Redis，負責存儲與業務相關的Cache數據，如用戶Profile、理財產品信息、用戶賬單信息等。實際落地數據存儲在MySQL中，該MySQL只進行了簡單的分庫分表及讀寫分離。

進行「秒殺」時，先由風控和運營人員選好理財產品，然後標記到數據庫中；活動開始由產品人員放開，終端用戶搶購。

該公司的業務主要來自移動端，平時流量較少，但「秒殺」活動時會瞬間產生大量流量，峯值併發達到10萬以上（其中可能包括bot），如此大的併發主要是集中在以下兩類接口：

其中uid是用戶ID，pid是理財產品ID，oid是訂單號，sid是隨着客戶端用戶變化的隨機token標識。

根據與客戶溝通得到的場景，初步得到了以下結論：

（1）客戶以移動業務爲主，產品通過API在客戶端渲染UI，產品中幾乎沒有靜態資源，帶寬流量不高，傳統CDN無法達到卸載壓力的作用；

基於以上兩點，我沒有建議該公司採購CDN服務，而是推薦服務擴容，但隨着我方對於業務更深層次的分析，逐漸發現了一些詭異的事情。

上述反常現象激起了雙方技術人員的興趣，這也許就是問題的關鍵！隨着分析深入，第一個現象的原因浮出水面：該公司在使用數據庫時，並未如某些大型電商平臺一樣使用數據庫中間件層進行MySQL請求的路由分發，而是在業務代碼端，使用語言層面的框架完成讀寫分離工作。這帶來了兩個弊端：

接着，第二個現象的原因也逐漸清晰：秒殺時，大量用戶訪問極少數理財產品，當這幾個產品的pid恰好被hash到同一個Redis上，就會導致Cache節點熱點失衡，所有請求最終集中在一個Redis，而這個Redis就是業務的瓶頸！

使用數據庫中間件可以帶來諸多好處，其中最重要的是可對業務層隱藏部分數據庫細節，更好地控制業務。當然，引入數據庫中間層也存在明顯缺點，在業務整體架構中增加一層組件，違反了「簡單有效」的設計原則。對於很多互聯網公司，在早期甚至中期沒有數據庫中間層也很正常。但當業務發展到一定階段，引入數據庫中間層是利大於弊的。

使用數據庫中間層，不僅可以解決性能問題，還能在安全方面起到作用，如審計、流量限制等，甚至攔截SQL注入、劣質SQL語句等。

Cache服務失衡是比較棘手的問題。「秒殺」時，用戶高頻訪問少數幾個理財產品信息，當其Cache數據恰巧分配在同一節點，大量請求會瞬間集中到一臺或少數幾臺節點，這就是Cache服務失衡的本質原因。不僅在電商「秒殺」場景中，其他有瞬間熱點訪問的業務類型也會存在這個問題。以微博爲例，曾因明星熱點事件導致接口緩慢甚至服務宕機，歸根到底也是這個原因。「爆料」的瞬間，一個微博會在短時間內海量傳播，該微博ID被同時打開，所有流量會集中到一個Redis節點。

這個問題如何解決？首先，Cache通常以某個數據結構的key爲維度進行hash存儲，大量用戶只訪問一個或幾個key時，將導致RedisCache節點負載不均衡，這是否一定對服務產生影響，則視併發情況而定，但這是一個巨大隱患。針對這個問題，客戶提出了一種解決方案：把一個理財產品的Cache數據再拆散，1個key變成多個，降低key被分配到同一Cache節點的概率。但這種方法存在很大弊端：

（2）日常所有get/set操作的時間消耗都將成倍增加，因爲1%的熱點事件增加99%常規操作的時間，嚴重違背二八法則。

API加速完全不同於傳統CDN的鏈路加速，通過緩存API返回內容並結合TCP廣域網優化技術，對API請求進行優化。白山API加速將每個API的response數據毫秒級緩存在全網邊緣節點，節點內存中的response數據以LRU（LeastRecentlyUsed）算法交換。在「熱點事件」時，最熱的信息持續保存在邊緣節點，當客戶端訪問該API時，邊緣節點可直接返回結果，不必返回源站。整個架構如下：

傳統觀點認爲，動態資源（API）無法緩存，但白山提出「任何資源都可以被緩存，只是過期時間不同」。對於常見的靜態資源，緩存過期時間較長；而API並非不能被緩存，只是過期時間很短。如一個查詢股價的API，可設定過期時間爲50毫秒；百米運動員起跑反應時間爲100-200毫秒，50毫秒對於PC端或移動端的用戶體驗並不會造成影響。

沒有緩存時，1秒內如有10000個用戶同時訪問，後端承受10000個併發；如果設置50毫秒的緩存時間，理論上可將後端併發降低到20個（1秒/50毫秒=20），後端負載降低至五百分之一，其他請求由緩存服務器直接返回給用戶。

綜上所述，白山API加速爲客戶提供毫秒級緩存，在不影響用戶體驗的前提下提高終端用戶響應速度，同時降低服務端的業務負載壓力。

API加速還支持自定義緩存規則，使其更貼近業務，包括QueryString、Header、Path三種類型，針對場景，設定如下規則：

GET/get_fprod.php?uid={$1}&pid={$2}&sid={$3}，每個理財產品都有獨立ID，產品信息不隨用戶ID和客戶端隨機信息變化，因此Cachekey可忽略URI中參數的{$1}和{$3}，/get_fprod.php?pid={$2}就是在邊緣節點存儲毫秒級的Cachekey。

緩存的過期時間如何確定呢？與業務相關，這需要對客戶提供的脫敏日誌進行分析，可初步設定過期時間爲500毫秒，最後還需考慮RTT修正值，以適應廣域網環境；RTT則由API加速服務自動捕捉並實時更新。

通過爲客戶主要的瓶頸接口配置API加速服務，並在峯值時間，從以下兩個維度對比API加速服務開啓與關閉時的效果：

如圖A所示，峯值期間終端用戶請求平均響應時間，從3秒左右壓縮至40毫秒以內；如圖B所示，峯值期間所有請求響應碼200的比例從70%左右提升至100%；圖C表示，峯值期間，後端CPUIdle從10%左右提高至97%左右。實測對比數據表明，API加速對降低平均響應時間、提升用戶體驗效果十分顯著，在降低後端服務器負載方面效果更加明顯，使用API加速的後端CPUIdle可保持在91%以上。

目前客戶最終落地數據庫請求直接請求到MySQL，未經隊列緩衝，建議使用隊列服務排隊處理峯值請求，其好處在於能在大訪問量時對請求進行調度，並可控制實際到達數據庫的併發，從而有效保護數據庫後端。

用戶日誌中含有大量明顯且規律的掃描軟件痕跡，如sqlmap、fimap等，雖然尚未對業務造成較大影響，但卻使服務端資源被佔用。建議在負載均衡最前端對掃描行爲予以屏蔽，以提高安全性，同時提升服務效率。除惡意Bot，搶單、刷單等行爲也會對服務產生影響，建議使用API防護服務識別與攔截。

該客戶在整體業務上，沒有服務降級設計，產品功能優先級未做劃分，導致重要的數據庫、Cache等衆多基礎服務混雜。一旦「秒殺」導致數據庫穿透等嚴重問題時，整體服務將不可用。這種情況應重新梳理業務單元，按照優先級切分基礎服務，首屏、產品列表、購買、訂單等信息優先級最高；其次是非重要功能，如評論、賬單等；如果後端負載較大，必要時可直接捨棄次要功能，從而降低後端負載，保證服務穩定。

解決類似「整點秒殺活動」的情景，是一個系統複雜的工程，就文中客戶暴露出來的數據庫負載不均勻、Cache緩存負載不均勻等問題，可通過採用數據庫中間層和API加速等技術解決，最終可取得理想效果。

上述「秒殺」案例，只是API加速的一個典型應用場景，接下來我還會撰文對API加速問題進行更爲系統的剖析。