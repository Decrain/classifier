過去的30餘年，科技圈的發展日新月異，如今大熱的機器學習更是常爆出「大新聞」，發展迅猛。但當我們把目光轉向學術刊物時，彷彿又回到了20世紀初：學術研究成果的呈現方式依舊停留在紙媒或者pdf文件上。

這一學術研究的大bug終於被注意到，並且在昨天有望被修補。

就在昨天，谷歌聯手OpenAI等宣佈發佈全新的服務於機器學習研究的交互視覺化期刊平臺——Distill（http://distill.pub/）。作爲一個網站平臺，Distill一方面爲學者發表和闡釋機器學習的研究成果提供了極大的便利，同時也爲大衆更深入清楚地瞭解機器學習的前沿發展打開了一扇窗戶。在一片叫好中，也有很多質疑的聲音。

過去，關於機器學習的科學實踐主要通過多種形式的「論文」來發布，如傳統期刊、arXiv掛靠、代碼庫和社區支持（JMLR和JAIR），以及多媒體的視頻、海報、博客等。Distill爲這些成果提供了一個更爲統一的出口，論文的價值也可以被評估。

另一方面，以arXiv這一現有論文發佈平臺爲依託，建立起來的評審方式（以ICLR的OpenReview環節爲例、LeCun與Bengio倡導的一種評審方式）有可能被顛覆。

昨天，GoogleBrain的ChrisOlah和ShanCarter發佈了Distill誕生的消息。從其幕後團隊看，Distill的出場已然自帶bgm。

之後，GoogleResearch、DeepMind、YC孵化器、OpenAI紛紛發文章進行介紹並表示支持和讚揚，IanGoodfellow等人在Twitter熱情轉發，Reddit機器學習版也在熱烈討論。

Distill的發佈還獲得了包括李飛飛、FrancoisChollet等許多業內知名學者的支持：

斯坦福大學人工智能實驗室主任、谷歌雲首席科學家李飛飛認爲這是促進AI民主化的重要方式。她提到的AI民主化包含了四步，分別是計算民主化、數據民主化、算法民主化、人才和專業知識的民主化。她認爲，「隨着科技觸及的人羣在變大，其影響也會變得更加深遠。這也是爲什麼，AI的下一步，必須是民主化（Democratization），減少准入障礙，對更大的社區開放，包括開發者、用戶和企業家。」（點擊查看大數據文摘關於李飛飛的相關報道《李飛飛四大視角看視覺智能：AI會改變世界，誰會改變AI》）

谷歌研究員，開源深度學習框架Keras的作者FrancoisChollet則稱讚Distill是在使機器學習成果更具說明性上邁出的第一步。

調參、可交互：Distill和一種嶄新又酷炫的思維方式

作爲新的平臺，Distill提供了一種嶄新的思維方式。

通過一些新的符號、視覺化以及模型，來幫助讀者理解機器學習最新研究。這種思維方式也爲研究者創造新發現提供可能。

爲了更好地說明自身的功能，Distill很貼心的在平臺上公開了幾篇學術作品給用戶作爲範例。大數據文摘挑選了一個發表在Distill官網上的使用神經網絡生成手寫字母（http://distill.pub/2016/handwriting/）的例子作爲說明，一起看看這個平臺有多炫酷。

在這篇文章中，作者利用神經網絡再生模型使計算機能夠「記憶」人的書寫習慣，進而模擬人的筆跡。

在文章開頭的第一個窗口，讀者可以用鼠標或電子筆任意書寫一些單詞甚至筆畫，然後通過調整上方的兩個參數：長度（Lengthofprediction）和偏差（Variation），讓計算機能在不同程度上模擬你的筆跡。這裏面綜合了輸入-記憶-模擬輸出的整個過程。

第二個窗口展示的計算機學習結果則更加驚人。首先，計算機模型書寫的內容更加接近真實的單詞，比如會出現「no」、「nean」、「Cran」等。其次，隨着偏差參數值減小，書寫筆跡更加統一，看起來好像出自同一人之手。

Distill提供的這種更加直觀、清晰的闡釋方式，在傳統紙媒期刊上是難以想象的。

Distill上的其他說明例子還包括：

對於剛剛誕生的Distill，並非所有的聲音都熱情洋溢。相比學術大佬們一邊倒的慶賀之態，Reddit等媒體平臺和twitter上則出現了大量讀者的質疑聲。

很多人認爲，Distill的一些屬性增加了研究者的工作量，而這些爲了展示所做的工作本來不是研究者的工作的重點。

「絕大多數機器學習研究者都不善於寫作，而編輯團隊不太可能去完成弄懂文章內容這樣繁重的工作。」

「寫好文章、製作易懂的交互圖像、管理GitHub記錄等，會消耗大量的時間。學者們本就時間緊張。」

「它要求你掌握Git分佈式版本控制系統、前後端的網頁設計，以及Java庫技術，這些又會大量佔用研究時間。」

Twitter上一位名叫@DelipRao的小哥連發25條推文表達對Distill的不滿，他稱，並非所有研究團隊都有經費能跟負擔Distill所要求的可視化呈現功能，這將導致學術研究民主化的倒退而非進步。

還有一些熱心讀者很積極的提出了給Distill的解決方案：

「比較好的方式是選取一些優秀的文章，爲Distill量身定做自己的版本，而不是將所有文章的第一版都發布在Distill上。」

「確實，弄出一篇Distill接受的好文章很費精力-做交互圖表，網頁設計等等。Distill能不能幫助研究者找一些這方面有能力並且願意參與的開發人員一起合作？」

不管是質疑還是反對，這個承載着很多希望的炫酷平臺都已然將在機器學習領域扮演重要角色。